{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['images_training.h5', 'labels_training.h5']\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import collections\n",
    "from scipy import linalg\n",
    "from time import gmtime, strftime, localtime\n",
    "\n",
    "print(os.listdir(\"../data/train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 784) (30000,)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('../data/train/images_training.h5','r') as H:\n",
    "    data_train = np.copy(H['datatrain'])\n",
    "with h5py.File('../data/train/labels_training.h5','r') as H:\n",
    "    label_train = np.copy(H['labeltrain'])\n",
    "\n",
    "# Checking dimensions of training data\n",
    "print(data_train.shape,label_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature scaling and Dimension Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,)\n",
      "(30000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Feature Scaling\n",
    "def feature_scaling(X, x_min, x_max):\n",
    "    nom = (X-X.min(axis=0))*(x_max-x_min)\n",
    "    denom = X.max(axis=0) - X.min(axis=0)\n",
    "    denom[denom==0] = 1  # divide by 0 adjustment\n",
    "    return x_min + nom/denom \n",
    "\n",
    "# apply function on training data\n",
    "# data_train_scaled = feature_scaling(data_train, -0.5, 0.5)\n",
    "# data_train_scaled = (data_train - data_train.mean(0)) / data_train.std(0)\n",
    "data_train_scaled = data_train / data_train.std(0)\n",
    "\n",
    "# print(data_train[0])\n",
    "print(data_train.std(0).shape)\n",
    "print(data_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature selection : 784\n"
     ]
    }
   ],
   "source": [
    "# Dimension reduction using SVD\n",
    "U, A, Vt = linalg.svd(data_train_scaled, full_matrices=False)\n",
    "\n",
    "# Selecting k dimensions\n",
    "k=784\n",
    "print(\"Feature selection : {}\".format(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing a sample data. The first example belongs to class 0: T-Shirt/Top\n",
    "- Figure 1 is reconstructed from SVD with k features.\n",
    "- Figure 2 is actual image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAU1UlEQVR4nO3df7BcdXnH8ffHkJDfcEkChBACDWnT0FbopClT1KEjOkhRcFqpcapxBhtbdUZb2+rgWClahzpVy0wdO1GoUZRfCgMqVRlKyzBVICBCKAKWCSEk5Cf5SS4kN0//2BNdwt3vd9mz9+7e+/28Zu7cvefZs/vs3vvcc/Y853y/igjMbPx7Ta8TMLPR4WI3K4SL3awQLnazQrjYzQrhYjcrhIt9BEh6r6R7ep3HaJJ0nqR1ifhXJV02iinZEVzs44Ck4yTdImmfpKclvavN9S6TtLf6GpQ01PTzo93MMSLeFxGfTeTS8p+FpP+U9FRTbi9JOtD083e7met4dVSvE7Cu+BLwEnACcCbwfUk/i4hkwVbF91lo7I0A74uI141wrq8gqeXfoaQZwO8AcyPiQLXsM8DJEfHe0clwfPCWvQZJ8yXdLGmrpO2S/rXF/a6S9Iyk3ZIekPT6ptgySWuq2GZJX6iWT5Z0bfW4OyXdL+mEYR57GvDHwCcjYm9E3APcBrx7hF7zhZIek7RH0gZJf3VE/O+q92OjpPc0Lb9W0uXV7fMkrav2LJ4DvgJ8FzilaWt9fLXqm4C7Dxd6JrdLqtyel3SHpIVNsW2S/kbS45J2SPo3SZPqvyNjh4u9Q5ImAN8DngZOBeYB17e4+/00trjHAd8CbpI0uYpdBVwVETOBhcCN1fIVwDHAfGAW8BfA/mEe+9eBoYh4omnZz4AzmnLdKalbW+x/By6NiMNb3P9uip0MTAFOqvL9sqSZLR7nZGA6cArwAeCtwPqImF59banudwHw/VxSks4ErgbeT2MP53+AW6vf02HLgXOBxcDvAX+dfbXjiIu9c8to/FH/bUTsi4jBaqv6ChFxbURsj4iDEfF54GjgN6rwAeB0SbOrLfNPmpbPAk6PiKGIeCAidg/z8NOBXUcs2wXMaHr+Y1vl1oEDwBJJMyJiR0Q82BQbBD4TEQci4jbgRRr/jIZzELg8Il6KiOH+iR12PvAfbeS1HLgpIu6OiJeAT9P4/ZzVdJ8vRsSm6h/JP1XrFMPF3rn5wNMRcTB3R0kfrXYvd0naSWOLPbsKX0qjIH5e7apfWC3/BvBD4Ppql/hzkiYO8/B7gSO3njOBPR28piPz/mTTbvXhjyhvB94GrJf0X5J+v2mVbREx1PTzCzT+GQ1nc1WUqec/C9gaERvbSPckGntZAFS/l4009rgOe6bp9tPVOsVwsXfuGRqfMZMHOavP5x8DLgEGIuJYGlteAUTEkxGxHDiextbm25KmVVvHf4iIJcAfABcC7xnmKZ4AjpK0qGnZa4HaR9Mj4tNNu9UfqpbdGxFvq/L9Hq0/umQfPvMztLkLX9kILDj8Q/V7OQl4tuk+85tun1KtUwwXe+fuAzYBV0qaVh1QO2eY+82gscu6lUZR/j1NW2JJfyZpTkQcAnZWi4ck/aGk364+c+6msfs8dMRjExH7gJuBK6o8zgEuorFn0FWSpkh6l6SZ1QGzPcPl1KHNwOzq6PthfwTc3ub61wN/Iumcag/oEzR+Pz9tus+HJZ0oaQ6Nf8A3dCHvMcPF3qFqd/WtwOnAemAD8KfD3PWHND5zPkFj13GQl+9Ong88KmkvjYN174yIQeBE4Ns0Cv0xGgfCrm2RzgdoHBjbAlwH/GVz263aDX99i3VfrRXA05J20/gI0pWj/hGxFvgOsK46oHg8jff23jbX/ymNg3NX0/jH+gbg4iM+VtxI4318AngQ+Hw3ch8r5MErrB+pcWLQhRHR1glCbTzeturxfpK98zjlLbv1qx009nSsS3wGnfWliPhBr3MYb7wbb1YI78abFWJUd+MlFbkbMXXq1GT8pJPS53Zs3749GX/++edfdU5jwcDAQK31x+v7khMRGm55rWKXdD6NgygTgK9GxJV1Hm+8WrJkSTJ+xRVXJOOrV69Oxm+4YXy2i88777xa6990001dymR86Hg3vjrZ40vAW4AlwHJJ6b9qM+uZOp/ZlwG/iIinqnOcr6dx5paZ9aE6xT6Pl58JtoGXX3QAgKSV1fXaa2o8l5nVVOcz+3AHAV5xAC4iVgGroNwDdGb9oM6WfQMvv4roZAq7ishsLKlT7PcDiySdVg3v804awyGZWR+qdQadpAuAf6HRersmIv4xc/9xuRu/Zk36cMSpp56ajP/4xz9OxnN99mnTprWMbdiwIbnu+vXrk/GdO3cm4zNmzEjGFyxY0DJ2+umnJ9fdvz81gE3+/IQzzjijZWzWrFnJdceyEemzR8TttH+9sZn1kE+XNSuEi92sEC52s0K42M0K4WI3K4SL3awQHpaqC+66665k/Oyzz07Gt27dmowfPJidh6KlXD/5mGOOScZfeik5jwOTJ09OxidOHG5ei4bdu4eb4OZXXnzxxWR88+bNyfjevXuT8dJ4y25WCBe7WSFc7GaFcLGbFcLFblYIF7tZIdx664LHH388GV+8eHEynmtvTZo0KRmfOfPI6dl/ZdeuXbWeO3cJ9ODgYDKeap/lhtg+dOhQrefOtTRL4y27WSFc7GaFcLGbFcLFblYIF7tZIVzsZoVwsZsVwn32Lsj1snP94Ne8Jv0/N3cpaOoy1lQPHmDPnj3JeK7PftRR6T+h1DkCuUt3c889NDSUjM+ZMycZL4237GaFcLGbFcLFblYIF7tZIVzsZoVwsZsVwsVuVgj32btgypQpyXida74hPRwzpKdlHhgYSK6bmu4Z8r1uadjZgX8p9dpz19LnXncut9x00qWpVeyS1gF7gCHgYEQs7UZSZtZ93diy/2FEbOvC45jZCPJndrNC1C32AH4k6QFJK4e7g6SVktZIWlPzucyshrq78edExEZJxwN3SPp5RNzdfIeIWAWsApCUPqJiZiOm1pY9IjZW37cAtwDLupGUmXVfx8UuaZqkGYdvA28G1nYrMTPrrjq78ScAt1R91qOAb0XED7qS1RiT61Xn+ui58dFz48anroffvn17ct2c3LX2EyZM6Dh+9NFHJ9fN9fBz18M/++yzLWO5cyP279+fjI9FHRd7RDwFvLaLuZjZCHLrzawQLnazQrjYzQrhYjcrhIvdrBC+xLULcu2p3JDHdeOp58+1t3Jtv1z7K/faU5ep1n3sXNsv9dpyzz0eectuVggXu1khXOxmhXCxmxXCxW5WCBe7WSFc7GaFcJ+9C3bu3JmM5/rkuX5xbsjkVLzulMu54Zxzcn3+OnLnCORee2m8ZTcrhIvdrBAudrNCuNjNCuFiNyuEi92sEC52s0K4z94FqSGL25G7bjvXq071wuv2+CdPnpyM54a5Tg2znbumPDec8549e5Lx1GvPTRc9HnnLblYIF7tZIVzsZoVwsZsVwsVuVggXu1khXOxmhXCfvQu2bduWjOf6ybleeG5q4tTj5/rouR5+bv3c1MepPnzu/IIDBw4k47lr8VPvW+49HY+yW3ZJ10jaImlt07LjJN0h6cnq+8DIpmlmdbWzG/814Pwjln0cuDMiFgF3Vj+bWR/LFntE3A3sOGLxRcDq6vZq4OIu52VmXdbpZ/YTImITQERsknR8qztKWgms7PB5zKxLRvwAXUSsAlYBSPIIgGY90mnrbbOkuQDV9y3dS8nMRkKnxX4bsKK6vQK4tTvpmNlIye7GS7oOOBeYLWkD8CngSuBGSZcC64F3jGSS/W5wcDAZz41vnus35+KpfnNu3PdcPHeOQG79XJ8+JddHz8Xnzp3b8XOPR9lij4jlLUJv7HIuZjaCfLqsWSFc7GaFcLGbFcLFblYIF7tZIXyJaxfkhjyu277KrZ8a7rluWy/XNsy11lLx3HO/+OKLyXjufStxuOgUb9nNCuFiNyuEi92sEC52s0K42M0K4WI3K4SL3awQ7rN3wQsvvJCM5/rkdfvwqXiuD5577oj04EK59VO99JG8tBdgx44jh04sm7fsZoVwsZsVwsVuVggXu1khXOxmhXCxmxXCxW5WCPfZuyB3zXdduWmRU332OtMaQ77Pnoun1OnRtyN3PXxpvGU3K4SL3awQLnazQrjYzQrhYjcrhIvdrBAudrNCuM/eBZMmTUrG582bl4xv3rw5Gc/12XPxlJE+RyB1PX3uHIC61+LnxgEoTXbLLukaSVskrW1adrmkZyU9VH1dMLJpmlld7ezGfw04f5jlX4yIM6uv27ublpl1W7bYI+JuwOP7mI1xdQ7QfUjSw9Vu/kCrO0laKWmNpDU1nsvMauq02L8MLATOBDYBn291x4hYFRFLI2Jph89lZl3QUbFHxOaIGIqIQ8BXgGXdTcvMuq2jYpc0t+nHtwNrW93XzPpDts8u6TrgXGC2pA3Ap4BzJZ0JBLAOeP8I5tj3jjnmmGQ8N355rt+cmn8d4Oijj24ZGxoaSq5bdw7zXC88lVuuT173Wvw65x+MR9lij4jlwyy+egRyMbMR5NNlzQrhYjcrhIvdrBAudrNCuNjNCuFLXLsgdwlrrsWUk7uENtWiGsmhoNtR57XnWmu5tuL06dM7fu7xyFt2s0K42M0K4WI3K4SL3awQLnazQrjYzQrhYjcrhPvsXbBsWXrsjlw/ODc1cW6459Rlqrle9YEDB5Lx3Pq5aZFfeOGFlrFcj3///v3J+ODgYDKeet9nzpyZXHf37t3J+FjkLbtZIVzsZoVwsZsVwsVuVggXu1khXOxmhXCxmxXCffYuWLhwYTKe62VPnTo1Gc/1slPXjOd69Lk+em79XC88N9R0Su5154bBTl3Pvnjx4uS69913XzI+FnnLblYIF7tZIVzsZoVwsZsVwsVuVggXu1khXOxmhWhnyub5wNeBE4FDwKqIuErSccANwKk0pm2+JCKeH7lU+9fAwEAyvmXLlmQ8Na0x5HvZqevhc33yXC87d45AnWvxc9ez180tdT17bgyCUvvsB4GPRsRvAmcDH5S0BPg4cGdELALurH42sz6VLfaI2BQRD1a39wCPAfOAi4DV1d1WAxePVJJmVt+r+swu6VTgLOBe4ISI2ASNfwjA8d1Ozsy6p+1z4yVNB74DfCQidrc7h5eklcDKztIzs25pa8suaSKNQv9mRNxcLd4saW4VnwsMexQqIlZFxNKIWNqNhM2sM9liV2MTfjXwWER8oSl0G7Ciur0CuLX76ZlZt7SzG38O8G7gEUkPVcsuA64EbpR0KbAeeMfIpNgfTjnllJax3GWcufZXroW0b9++ZDz1/LlhrOtOi5xrj6Vee93nzr1vqaGmlyxZklx3PMoWe0TcA7T6gP7G7qZjZiPFZ9CZFcLFblYIF7tZIVzsZoVwsZsVwsVuVggPJd2m0047rWWs7pTLuX5xTp3hmnO51Y2net25S1xz6rzu+fPn13ruschbdrNCuNjNCuFiNyuEi92sEC52s0K42M0K4WI3K4T77G2aOXNmy1jdXnTuuu6c1Pq54cNyve7c+nWmfM69L7nzF+pI/T7HK2/ZzQrhYjcrhIvdrBAudrNCuNjNCuFiNyuEi92sEO6zt2nBggUtY3V71bn1c+On15HrZefidcd+ryOX28SJE1vGpk6dmlx39uzZyfi2bduS8X7kLbtZIVzsZoVwsZsVwsVuVggXu1khXOxmhXCxmxUi22eXNB/4OnAicAhYFRFXSboc+HNga3XXyyLi9pFKtNemTJnSMpbro9cdV76O3HPncs+pe45BHXXOEdi+fXty3RNPPDEZH4t99nZOqjkIfDQiHpQ0A3hA0h1V7IsR8c8jl56ZdUu22CNiE7Cpur1H0mPAvJFOzMy661V9Zpd0KnAWcG+16EOSHpZ0jaSBFuuslLRG0ppamZpZLW0Xu6TpwHeAj0TEbuDLwELgTBpb/s8Pt15ErIqIpRGxtAv5mlmH2ip2SRNpFPo3I+JmgIjYHBFDEXEI+AqwbOTSNLO6ssWuxuHUq4HHIuILTcvnNt3t7cDa7qdnZt3SztH4c4B3A49IeqhadhmwXNKZQADrgPePSIZ9YvHixS1js2bNSq67b9++WvHclM6py0hzl5jm4qnLRKFe2/Coo9J/fql2J+SHgx4YGPYwEgALFy5Mrrto0aJkfO3asbdta+do/D3AcM3ScdtTNxuPfAadWSFc7GaFcLGbFcLFblYIF7tZIVzsZoXwUNJtmjBhQsvYueeem1z3ueeeS8Z37dqVjO/du7fj9XM9+tTrakduKOnBwcGWsVyf/dhjj03G58yZk4yn3rfcJaobN25Mxscib9nNCuFiNyuEi92sEC52s0K42M0K4WI3K4SL3awQyg0F3NUnk7YCTzctmg3065i8/Zpbv+YFzq1T3cxtQUQMewLCqBb7K55cWtOvY9P1a279mhc4t06NVm7ejTcrhIvdrBC9LvZVPX7+lH7NrV/zAufWqVHJraef2c1s9PR6y25mo8TFblaInhS7pPMlPS7pF5I+3oscWpG0TtIjkh7q9fx01Rx6WyStbVp2nKQ7JD1ZfW89OPro53a5pGer9+4hSRf0KLf5ku6S9JikRyV9uFre0/cukdeovG+j/pld0gTgCeBNwAbgfmB5RPzvqCbSgqR1wNKI6PkJGJLeAOwFvh4Rv1Ut+xywIyKurP5RDkTEx/okt8uBvb2exruarWhu8zTjwMXAe+nhe5fI6xJG4X3rxZZ9GfCLiHgqIl4Crgcu6kEefS8i7gZ2HLH4ImB1dXs1jT+WUdcit74QEZsi4sHq9h7g8DTjPX3vEnmNil4U+zzgmaafN9Bf870H8CNJD0ha2etkhnFCRGyCxh8PcHyP8zlSdhrv0XTENON98951Mv15Xb0o9uGmkuqn/t85EfG7wFuAD1a7q9aetqbxHi3DTDPeFzqd/ryuXhT7BmB+088nA30zul9EbKy+bwFuof+mot58eAbd6vuWHufzS/00jfdw04zTB+9dL6c/70Wx3w8sknSapEnAO4HbepDHK0iaVh04QdI04M3031TUtwErqtsrgFt7mMvL9Ms03q2mGafH713Ppz+PiFH/Ai6gcUT+/4BP9CKHFnn9GvCz6uvRXucGXEdjt+4AjT2iS4FZwJ3Ak9X34/oot28AjwAP0yisuT3K7XU0Pho+DDxUfV3Q6/cukdeovG8+XdasED6DzqwQLnazQrjYzQrhYjcrhIvdrBAudrNCuNjNCvH/I1Axqs/OLHAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reconstructing and visualising truncated data\n",
    "data_train_reconstuct = np.dot(U[:,0:k], np.dot(np.diag(A[0:k]),Vt[0:k,:]))\n",
    "\n",
    "data_recon_shaped = data_train_reconstuct.reshape((data_train_reconstuct.shape[0], 28, 28))\n",
    "data_train_shaped = data_train.reshape((data_train.shape[0], 28, 28))\n",
    "\n",
    "plt.imshow(data_recon_shaped[0], cmap=plt.get_cmap('gray'))\n",
    "plt.title(\"class \" + str(label_train[0]) + \": T-shirt/Top\" )\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(data_train_shaped[0], cmap=plt.get_cmap('gray'))\n",
    "plt.title(\"class \" + str(label_train[0]) + \": T-shirt/Top\" )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Truncated SVD based on k features selection\n",
    "# This truncated data will be used for training and validation\n",
    "# Overwriting training data with truncated training data\n",
    "# data_train = np.dot(U[:,0:k], np.diag(A[0:k]))\n",
    "data_train = data_train_scaled\n",
    "\n",
    "# Checking dimension\n",
    "print(data_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression and optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid function\n",
    "def sigmoid_function(x):\n",
    "    return (1 / (1 + np.exp(-x)))\n",
    "\n",
    "# Loss/cross entropy function - log likelihood\n",
    "def cross_entropy_error_e(features_x, label_y, theta_s):\n",
    "    sigma = sigmoid_function(features_x @ theta_s)\n",
    "    sigma[sigma == 1] = 0.999999 # avoid 0 for log(1)\n",
    "    \n",
    "    entropy_error = label_y.T @ np.log(sigma) + (1 - label_y).T @ np.log(1 - sigma)\n",
    "    entropy_error = -1 * entropy_error\n",
    "    return entropy_error / len(label_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss/cross entropy function - log likelihood\n",
    "# Added regularisation paramter \"lambda\"\n",
    "def cross_entropy_error_regularized(features_x, label_y, theta_s, lambda_r):\n",
    "    sigma = sigmoid_function(features_x @ theta_s)\n",
    "    sigma[sigma == 1] = 0.999999 # avoid 0 for log(1)\n",
    "    \n",
    "    entropy_error = label_y.T @ np.log(sigma) + (1 - label_y).T @ np.log(1 - sigma)\n",
    "    entropy_error = (-1 * entropy_error) + ((lambda_r/2) * theta_s.T @ theta_s)\n",
    "    return entropy_error / len(label_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient descent for optimisation\n",
    "def gradient_descent_gd(features_x, label_y, learn_rate, num_iter, lambda_r):\n",
    "    num_features = features_x.shape[1]\n",
    "    theta = np.zeros(num_features)\n",
    "    entropy_error_hist = np.zeros((num_iter,1))\n",
    "    \n",
    "    for i in range(num_iter):\n",
    "        sigma = sigmoid_function(features_x @ theta)\n",
    "        theta -= (learn_rate * (features_x.T @ (sigma - label_y))) / len(label_y)\n",
    "        entropy_error_hist[i] = cross_entropy_error_regularized(features_x, label_y, theta_s=theta, lambda_r=lambda_r)\n",
    "    return entropy_error_hist, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging labels with features before random folds\n",
    "data_combined = np.c_[data_train, label_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating validation and train data based on random index\n",
    "indices = np.random.permutation(data_combined.shape[0])\n",
    "# Traing set - 50%\n",
    "# Validation set 1 - 10%\n",
    "# Validation set 2 - 10%\n",
    "training_idx, validation_idx = indices[:int(0.5*data_combined.shape[0])], indices[int(0.7*data_combined.shape[0]):int(0.8*data_combined.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding 1's for constant weight w0\n",
    "data_combined = np.c_[np.ones(data_combined.shape[0]), data_combined]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 786)\n"
     ]
    }
   ],
   "source": [
    "training_set, validation_set = data_combined[training_idx,:], data_combined[validation_idx,:]\n",
    "print(training_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find optimum learning rate and lamda for one label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from math import ceil\n",
    "\n",
    "# # find optimum learning rate and lamda for one label\n",
    "# label_learn = (training_set[:,k+1] == 7).astype(int)\n",
    "# init_theta = np.zeros(training_set.shape[1] - 1)\n",
    "\n",
    "# # Initial loss/cost\n",
    "# entropy_initial = cross_entropy_error_regularized(features_x=training_set[:,0:(k+1)],label_y=label_learn,theta_s=init_theta, lambda_r=2)\n",
    "# print(\"Initial cost with theta = 0 for item {} is : {}\".format(0, entropy_initial))\n",
    "\n",
    "# num_iters = 5000\n",
    "# # sample learning rates\n",
    "# learning_rates = [0.01, 0.02,0.05, 0.1]\n",
    "# # sample lambda\n",
    "# lambda_rate = [2,5]\n",
    "\n",
    "# print(\"Starting learning for item : 7\")\n",
    "# plt.figure(figsize=(14,8))\n",
    "# leg = []\n",
    "\n",
    "# for lr in learning_rates:\n",
    "#     print(\"Learning rate set to : {} ...\".format(lr))\n",
    "#     for lm in lambda_rate:\n",
    "#         cost_history, temp = gradient_descent_gd(features_x=training_set[:,0:(k+1)], label_y=label_learn, learn_rate=lr, num_iter=num_iters, lambda_r=lm)\n",
    "#         leg.append(str(lr) + \" and \" + str(lm))\n",
    "#         plt.plot(cost_history, linewidth=2)\n",
    "\n",
    "# plt.title(\"Convergence plots for different learning rates\")\n",
    "# plt.xlabel(\"number of iterations\", fontsize=14)\n",
    "# plt.ylabel(\"cost\", fontsize=14)\n",
    "# plt.legend(list(map(str, leg)))\n",
    "# plt.axis([0, num_iters, 0, 0.7])\n",
    "# plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon, 21 Oct 2019 19:24:15 +0000\n"
     ]
    }
   ],
   "source": [
    "# registering time for perfomance measurement\n",
    "start = time.time()\n",
    "print(strftime(\"%a, %d %b %Y %H:%M:%S +0000\", localtime()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training and find accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier size : (10, 785)\n",
      "-------------------------------------------------------\n",
      "Training accuracy: 83.68666666666667%\n",
      "-------------------------------------------------------\n",
      "Mon, 21 Oct 2019 19:25:58 +0000\n",
      "CPU times: user 3min 15s, sys: 2.74 s, total: 3min 18s\n",
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training data\n",
    "X = training_set[:,0:(k+1)]\n",
    "# Labels for training set\n",
    "y = training_set[:,k+1]\n",
    "# Initializing classifier for each label\n",
    "classifiers = np.zeros(shape=(10, training_set.shape[1] - 1))\n",
    "print(\"Classifier size : {}\".format(classifiers.shape))\n",
    "\n",
    "for c in range(0, 10):\n",
    "    label = (y == c).astype(int)\n",
    "    _, classifiers[c, :] = gradient_descent_gd(features_x=X, label_y=label, learn_rate=0.015, num_iter=800, lambda_r=10)\n",
    "\n",
    "# Predicting probabilities\n",
    "classProbabilities = sigmoid_function(X @ classifiers.transpose())\n",
    "\n",
    "# labeling data based on maximum probability\n",
    "predictions = classProbabilities.argmax(axis=1)\n",
    "\n",
    "# Accuracy measurement for training data\n",
    "print(\"-------------------------------------------------------\")\n",
    "print(\"Training accuracy:\", str(100 * np.mean(predictions == y)) + \"%\")\n",
    "print(\"-------------------------------------------------------\")\n",
    "print(strftime(\"%a, %d %b %Y %H:%M:%S +0000\", localtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({4: 1724, 9: 1605, 7: 1600, 3: 1593, 8: 1518, 2: 1511, 0: 1490, 1: 1479, 5: 1344, 6: 1136})\n"
     ]
    }
   ],
   "source": [
    "# Prediction distribution\n",
    "print(collections.Counter(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate set 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "validation accuracy: 81.76666666666667%\n",
      "-------------------------------------------------------\n",
      "Prediction distribution for Validation set 1 : Counter({4: 342, 2: 332, 3: 331, 9: 328, 1: 301, 7: 298, 0: 294, 8: 289, 5: 255, 6: 230})\n",
      "--- Total time taken in Training and Validation ---\n",
      "--- 103.09307909011841 sec ---\n",
      "Mon, 21 Oct 2019 19:25:58 +0000\n",
      "CPU times: user 13.1 ms, sys: 1.88 ms, total: 15 ms\n",
      "Wall time: 6.56 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Applying classifier on validation set 1\n",
    "X = validation_set[:,0:(k+1)]\n",
    "y = validation_set[:,(k+1)]\n",
    "\n",
    "classProbabilities = sigmoid_function(X @ classifiers.transpose())\n",
    "predictions = classProbabilities.argmax(axis=1)\n",
    "print(\"-------------------------------------------------------\")\n",
    "print(\"validation accuracy:\", str(100 * np.mean(predictions == y)) + \"%\")\n",
    "print(\"-------------------------------------------------------\")\n",
    "\n",
    "print(\"Prediction distribution for Validation set 1 : {}\".format(collections.Counter(predictions)))\n",
    "print(\"--- Total time taken in Training and Validation ---\")\n",
    "print(\"--- %s sec ---\" % (time.time() - start))\n",
    "print(strftime(\"%a, %d %b %Y %H:%M:%S +0000\", localtime()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate set 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "validation set 2 accuracy: 81.73333333333333%\n",
      "-------------------------------------------------------\n",
      "Prediction distribution for Validation set 2 : Counter({4: 353, 3: 352, 9: 328, 8: 324, 7: 320, 2: 311, 1: 292, 0: 268, 5: 246, 6: 206})\n",
      "Counter({4: 353, 3: 352, 9: 328, 8: 324, 7: 320, 2: 311, 1: 292, 0: 268, 5: 246, 6: 206})\n",
      "--- 103.11717700958252 sec ---\n",
      "Mon, 21 Oct 2019 19:25:58 +0000\n",
      "CPU times: user 26.2 ms, sys: 7.79 ms, total: 34 ms\n",
      "Wall time: 16.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Applying classifier on validation set 2\n",
    "validation_idx_2 = indices[int(0.8*data_combined.shape[0]):int(0.9*data_combined.shape[0])]\n",
    "validation_set_2 = data_combined[validation_idx_2,:]\n",
    "\n",
    "X = validation_set_2[:,0:(k+1)]\n",
    "y = validation_set_2[:,(k+1)]\n",
    "classProbabilities = sigmoid_function(X @ classifiers.transpose())\n",
    "predictions = classProbabilities.argmax(axis=1)\n",
    "print(\"-------------------------------------------------------\")\n",
    "print(\"validation set 2 accuracy:\", str(100 * np.mean(predictions == y)) + \"%\")\n",
    "print(\"-------------------------------------------------------\")\n",
    "\n",
    "print(\"Prediction distribution for Validation set 2 : {}\".format(collections.Counter(predictions)))\n",
    "print(collections.Counter(predictions))\n",
    "print(\"--- %s sec ---\" % (time.time() - start))\n",
    "print(strftime(\"%a, %d %b %Y %H:%M:%S +0000\", localtime()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross check classifiers against Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data size : (10000, 784)\n",
      "(2000,) (10, 785) (785, 10)\n",
      "-------------------------------------------------------\n",
      "Testing accuracy: 82.15%\n",
      "-------------------------------------------------------\n",
      "Mon, 21 Oct 2019 19:25:59 +0000\n",
      "CPU times: user 1.16 s, sys: 112 ms, total: 1.27 s\n",
      "Wall time: 685 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with h5py.File('../data/test/images_testing.h5','r') as H:\n",
    "    data_pred = np.copy(H['datatest'])\n",
    "with h5py.File('../data/test/labels_testing_2000.h5','r') as H:\n",
    "    label_pred = np.copy(H['labeltest'])\n",
    "               \n",
    "# Feature scaling for test data\n",
    "# data_pred_scaled = feature_scaling(data_pred, -0.5, 0.5)\n",
    "# data_pred_scaled = (data_pred - data_pred.mean(0)) / data_pred.std(0)\n",
    "data_pred_scaled = data_pred / data_pred.std(0)\n",
    "\n",
    "# SVD on test data to match classifier dimension\n",
    "U_test, A_test, Vt_test = linalg.svd(data_pred_scaled, full_matrices=False)\n",
    "# data_pred = np.dot(U_test[:,0:k], np.diag(A_test[0:k]))\n",
    "data_pred = data_pred_scaled\n",
    "print(\"Test data size : {}\".format(data_pred.shape))\n",
    "\n",
    "# padding 1's\n",
    "data_pred_combined = np.c_[np.ones(data_pred.shape[0]), data_pred]\n",
    "\n",
    "# Selecting first 2000 samples with labels\n",
    "X = data_pred_combined[0:2000,:]\n",
    "y = label_pred\n",
    "\n",
    "# Predicting output labels\n",
    "classProbabilities = sigmoid_function(X @ classifiers.transpose())\n",
    "# classProbabilities = sigmoid_function(np.dot(X, classifiers.transpose()))\n",
    "predictions = classProbabilities.argmax(axis=1)\n",
    "print(predictions.shape, classifiers.shape, classifiers.transpose().shape)\n",
    "\n",
    "print(\"-------------------------------------------------------\")\n",
    "print(\"Testing accuracy:\", str(100 * np.mean(predictions == y)) + \"%\")\n",
    "print(\"-------------------------------------------------------\")\n",
    "print(strftime(\"%a, %d %b %Y %H:%M:%S +0000\", localtime()))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
